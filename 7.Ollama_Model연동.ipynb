{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1109fc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama is running\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"http://127.0.0.1:11434\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0482fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "('<think>\\n'\n",
      " \"Alright, so I'm trying to understand what LangChain is. From the previous \"\n",
      " 'explanation, it seems like a tool for integrating language models into '\n",
      " \"machine learning workflows. But now I'm wondering if there's more to it or \"\n",
      " 'how exactly it works.\\n'\n",
      " '\\n'\n",
      " 'First off, I know that in machine learning, we often use datasets and models '\n",
      " 'to train systems. So maybe LangChain provides some extra functionality '\n",
      " 'beyond just using existing libraries. It might help with processing these '\n",
      " 'datasets further before feeding them into the model.\\n'\n",
      " '\\n'\n",
      " \"I've heard of NLP tasks like text classification or sentiment analysis. Does \"\n",
      " \"LangChain handle those? I'm not sure how it would integrate into a typical \"\n",
      " 'workflow. Would you need to use external libraries for that, or does it '\n",
      " 'simplify things by handling some of the preprocessing?\\n'\n",
      " '\\n'\n",
      " 'Another thing is that maybe LangChain allows for more flexible model '\n",
      " 'configurations. Like, instead of just using a single model, could one '\n",
      " 'experiment with different architectures? Or perhaps adjust hyperparameters '\n",
      " \"in a way that's integrated into the Langchain framework.\\n\"\n",
      " '\\n'\n",
      " \"I'm also thinking about data pipelines. In machine learning workflows, it's \"\n",
      " 'common to have steps like data loading, cleaning, and transforming data '\n",
      " 'before feeding it into models. Does LangChain offer some of these steps as '\n",
      " 'part of its integration process, making it easier for someone to set up a '\n",
      " 'complete pipeline without having to write extensive code from scratch?\\n'\n",
      " '\\n'\n",
      " 'Moreover, I recall that sometimes tools or libraries provide specific '\n",
      " 'datasets for certain tasks. If LangChain is the right tool for integrating '\n",
      " 'language models, maybe it could provide access to new or specialized '\n",
      " \"datasets that aren't available elsewhere, which would be beneficial for \"\n",
      " 'researchers and developers.\\n'\n",
      " '\\n'\n",
      " \"I'm also curious about how accurate and efficient it is compared to other \"\n",
      " \"methods. Since it's a language model-based system, might there be \"\n",
      " 'limitations in accuracy due to the nature of the data? Or are there ways to '\n",
      " 'mitigate those issues?\\n'\n",
      " '\\n'\n",
      " 'Another aspect to consider is community support and resources. If someone '\n",
      " 'uses LangChain for their work, does they have access to tutorials or '\n",
      " 'documentation to help them get started? That could make it more '\n",
      " 'user-friendly compared to using other tools that might require more setup '\n",
      " 'from the beginning.\\n'\n",
      " '\\n'\n",
      " \"I should also think about potential downsides. Maybe there's a learning \"\n",
      " \"curve involved if someone isn't familiar with integrating language models \"\n",
      " 'with machine learning workflows. Or perhaps the integration is done in a way '\n",
      " 'that makes things more complicated than necessary, requiring users to '\n",
      " 'implement certain steps themselves.\\n'\n",
      " '\\n'\n",
      " 'In summary, LangChain seems like a tool that enhances the process of using '\n",
      " 'language models by providing pre-processed data, flexible model '\n",
      " \"configurations, and possibly new datasets. However, I'm not entirely sure \"\n",
      " 'how all these elements work together within a typical machine learning '\n",
      " 'workflow or if there are potential limitations to consider.\\n'\n",
      " '</think>\\n'\n",
      " '\\n'\n",
      " 'LangChain is a versatile tool designed to simplify the integration of '\n",
      " \"language models into machine learning workflows. Here's a structured \"\n",
      " 'overview of its key features and considerations:\\n'\n",
      " '\\n'\n",
      " '1. **Integration with Language Models**: LangChain leverages existing '\n",
      " 'libraries, offering a seamless transition from data processing to model '\n",
      " 'training.\\n'\n",
      " '\\n'\n",
      " '2. **Data Handling**: It provides functions for preprocessing datasets, '\n",
      " 'which can streamline tasks like text classification or sentiment analysis by '\n",
      " 'reducing the need for extensive external tools.\\n'\n",
      " '\\n'\n",
      " '3. **Model Experimentation**: LangChain allows experimentation with various '\n",
      " 'language models and hyperparameters, facilitating deeper understanding '\n",
      " 'through iterative adjustments.\\n'\n",
      " '\\n'\n",
      " '4. **Comprehensive Data Pipelines**: The tool facilitates a well-rounded '\n",
      " 'data pipeline, encompassing loading, cleaning, transforming, and '\n",
      " 'preprocessing steps essential for robust model training.\\n'\n",
      " '\\n'\n",
      " '5. **Specialized Datasets**: It offers access to new datasets tailored for '\n",
      " 'specific tasks, enhancing the reach of language models beyond standard '\n",
      " 'datasets.\\n'\n",
      " '\\n'\n",
      " '6. **Accuracy Considerations**: While leveraging the power of language '\n",
      " 'models, potential limitations in dataset quality may affect accuracy, though '\n",
      " 'tools exist to mitigate these issues through careful data preparation.\\n'\n",
      " '\\n'\n",
      " '7. **Community Support and Resources**: Tutorials and documentation can be '\n",
      " 'invaluable for new users, ensuring a user-friendly experience compared to '\n",
      " 'more complex integration methods.\\n'\n",
      " '\\n'\n",
      " '8. **Learning Curve**: While beneficial, the need to set up certain steps '\n",
      " 'might require some initial learning, potentially deterring those unfamiliar '\n",
      " 'with integrating language models into workflows.\\n'\n",
      " '\\n'\n",
      " 'In conclusion, LangChain enhances machine learning workflows by providing '\n",
      " 'pre-processed data and model configurations, but its effectiveness may '\n",
      " 'depend on factors such as dataset quality and user familiarity.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "#from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pprint import pprint\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 llama3.2 모델 로드\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "# prompt_template = PromptTemplate.from_template(\"Q: {question}\\nA:\")\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"What is LangChain?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(type(response))\n",
    "\n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86cf396d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking, \"파이썬은 무엇인가요?\" which translates to \"What is Python?\" in English. I need to provide a clear and accurate answer.\n",
      "\n",
      "First, I should start by defining Python as a programming language. Mention that it's widely used for various purposes like web development, data analysis, artificial intelligence, and more. It's known for its simplicity and readability.\n",
      "\n",
      "I should also highlight its features, such as a large standard library, easy-to-learn syntax, and cross-platform compatibility. Maybe mention that it's open-source and has a vast community. \n",
      "\n",
      "It's important to note that Python is not just for beginners; it's also used by professionals. Examples of popular frameworks like Django and Flask can illustrate its applications. \n",
      "\n",
      "I should avoid technical jargon and keep the explanation straightforward. Make sure to explain why Python is popular, like its readability and versatility. Also, mention that it's used in both small scripts and large-scale projects.\n",
      "\n",
      "Check for any misconceptions. For instance, while Python is easy to learn, it's not the only language for data analysis. Also, note that it's not just for data science but has many other uses. \n",
      "\n",
      "Finally, conclude by emphasizing Python's role in the tech industry and its importance in various fields. Keep the answer concise but comprehensive.\n",
      "</think>\n",
      "\n",
      "파이썬은 프로그래밍 언어로, 간결하고 읽기 쉽게 설계된 언어로, 다양한 분야에서 널리 사용됩니다. 주요 특징은 다음과 같습니다:\n",
      "\n",
      "1. **간결한 문법**:  \n",
      "   파이썬은 '명확한 구문'을 통해 코드를 작성할 수 있어, 초반 배우기 쉬운 점이 특징입니다. 예:  \n",
      "   ```python\n",
      "   print(\"Hello, World!\")\n",
      "   ```\n",
      "\n",
      "2. **다양한 활용 분야**:  \n",
      "   - **웹 개발**: Django, Flask 등 프레임워크 사용  \n",
      "   - **데이터 분석**: Pandas, NumPy, Matplotlib 등 라이브러리 활용  \n",
      "   - **AI/머신러닝**: TensorFlow, PyTorch 등 라이브러리 사용  \n",
      "   - **데이터 과학**: Scikit-learn, Keras 등 도구  \n",
      "   - **제작**: GUI 앱( PyQt, Tkinter), 템플릿 마크업( Jinja2) 등  \n",
      "\n",
      "3. **크로스플랫폼 호환성**:  \n",
      "   Windows, macOS, Linux 등 다양한 운영 체제에서 동작 가능하며, 배포 시도 필요 없음.\n",
      "\n",
      "4. **크로스-프로젝트 지원**:  \n",
      "   대규모 커뮤니티와 오픈소스 기반으로, 빠르게 발전 중이며, 라이브러리(예: Flask, Django)가 풍부합니다.\n",
      "\n",
      "5. **보안 강화**:  \n",
      "   웹 앱 개발 시 안정적인 구조로, 인증/인가 과정에서 유용합니다.\n",
      "\n",
      "**특징 요약**:  \n",
      "- **편리한 문법** + **다양한 활용** + **크로스플랫폼** + **대규모 커뮤니티**  \n",
      "- **초보자도 쉽게 배우고, 프로젝트부터 대규모 개발까지 활용 가능**\n",
      "\n",
      "파이썬은 기술 분야에서 빠르게 확장되고 있으며, 데이터 과학, AI, 웹 개발 등 다양한 분야에서 핵심 역할을 합니다. 🐍\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 llama3.2 모델 로드\n",
    "llm = ChatOllama(model=\"qwen3:1.7b\")\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"파이썬은 무엇인가요?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-AGfTwH54-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
