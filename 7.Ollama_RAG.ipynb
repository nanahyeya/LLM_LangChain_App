{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    pip install -U langchain langchain-core langchain-commnity langchain-experimental langchain-huggingface langchain-ollama\n",
    "    pip install streamlit --upgrade\n",
    "    pip install sentence-transformers\n",
    "    pip install pdfplumber faiss-cpu pydantic\n",
    "'''\n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# 색상 팔레트 정의\n",
    "primary_color = \"#1E90FF\"  # 기본 색상\n",
    "secondary_color = \"#FF6347\"  # 보조 색상\n",
    "background_color = \"#F5F5F5\"  # 배경 색상\n",
    "text_color = \"#4561e9\"  # 텍스트 색상\n",
    "\n",
    "# 사용자 정의 CSS 적용\n",
    "st.markdown(f\"\"\"\n",
    "    <style>\n",
    "    .stApp {{\n",
    "        background-color: {background_color};\n",
    "        color: {text_color};\n",
    "    }}\n",
    "    .stButton>button {{\n",
    "        background-color: {primary_color};\n",
    "        color: white;\n",
    "        border-radius: 5px;\n",
    "        border: none;\n",
    "        padding: 10px 20px;\n",
    "        font-size: 16px;\n",
    "    }}\n",
    "    .stTextInput>div>div>input {{\n",
    "        border: 2px solid {primary_color};\n",
    "        border-radius: 5px;\n",
    "        padding: 10px;\n",
    "        font-size: 16px;\n",
    "    }}\n",
    "    .stFileUploader>div>div>div>button {{\n",
    "        background-color: {secondary_color};\n",
    "        color: white;\n",
    "        border-radius: 5px;\n",
    "        border: none;\n",
    "        padding: 10px 20px;\n",
    "        font-size: 16px;\n",
    "    }}\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Streamlit 앱 제목 설정\n",
    "st.title(\"Ollama 기반 RAG 시스템 구축\")\n",
    "\n",
    "# PDF 파일 업로드\n",
    "uploaded_file = st.file_uploader(\"PDF 파일을 업로드하세요\", type=\"pdf\")\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    # 업로드된 파일을 임시 위치에 저장\n",
    "    with open(\"temp.pdf\", \"wb\") as f:\n",
    "        f.write(uploaded_file.getvalue())\n",
    "\n",
    "    # PDF 로더 초기화\n",
    "    loader = PDFPlumberLoader(\"temp.pdf\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    # 문서 분할기 초기화\n",
    "    text_splitter = SemanticChunker(HuggingFaceEmbeddings())\n",
    "    documents = text_splitter.split_documents(docs)\n",
    "\n",
    "    # 임베딩 모델 초기화\n",
    "    embedder = HuggingFaceEmbeddings()\n",
    "\n",
    "    # 벡터 스토어 생성 및 임베딩 추가\n",
    "    vector = FAISS.from_documents(documents, embedder)\n",
    "    retriever = vector.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "    # LLM 정의\n",
    "    llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "    #llm = ChatOllama(model=\"qwen2.5:1.5b\")\n",
    "\n",
    "    # # 시스템 프롬프트 정의\n",
    "    # system_prompt = (\n",
    "    # \"주어진 문맥을 참고하여 질문에 답하세요. \"\n",
    "    # \"답을 모를 경우, '모르겠습니다'라고만 답하고 스스로 답을 만들지 마세요. \"\n",
    "    # \"답변은 최대 3문장으로 간결하게 작성하세요. \"\n",
    "    # \"최종 답변은 무조건 한국어(korean)으로 작성해주세요\"\n",
    "    # \"문맥: {context}\"\n",
    "    # )\n",
    "\n",
    "    system_prompt = (\n",
    "        \"Answer the question with reference to the given context.\"\n",
    "        \"If you don't know the answer, just say 'I don't know' and don't make up your own answer.\"\n",
    "        \"Please write your answer concisely, with a maximum of 3 sentences.\"\n",
    "        \"Please write your final answer in Korean (Korean) without fail.\"\n",
    "        \"Context: {context}\"\n",
    "    )\n",
    "\n",
    "    # ChatPromptTemplate 정의\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 문서 결합 체인 생성\n",
    "    combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    # 검색 기반 QA 체인 생성\n",
    "    rag_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "\n",
    "    # 사용자 입력 받기\n",
    "    user_input = st.text_input(\"PDF와 관련된 질문을 입력하세요:\")\n",
    "\n",
    "    # 사용자 입력 처리\n",
    "    if user_input:\n",
    "        with st.spinner(\"처리 중...\"):\n",
    "            response = rag_chain.invoke({\"input\": user_input})\n",
    "            st.write(\"응답:\")\n",
    "            st.write(response.get(\"answer\",\"응답을 처리할 수 없습니다.\"))\n",
    "else:\n",
    "    st.write(\"진행하려면 PDF 파일을 업로드하세요.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
