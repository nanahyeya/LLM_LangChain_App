{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab9a673e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "981e738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f6aad7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"파이썬은 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15336d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000002489C36FA70> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002489C847EC0> root_client=<openai.OpenAI object at 0x000002489A10C2F0> root_async_client=<openai.AsyncOpenAI object at 0x000002489C455E20> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd9097ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "<class 'str'>\n",
      "응답: 파이썬! 프로그래밍 세계에서 매우 인기 있는 언어입니다. 저는 개발자로서 파이썬에 대해 자세히 설명해 드리겠습니다.\n",
      "\n",
      "**파이썬이란?**\n",
      "\n",
      "파이썬은 1991년 Guido van Rossum에 의해 개발된 고수준 프로그래밍 언어입니다. 파이썬은 동적 타이핑(dynamic typing) 언어이며, 객체 지향 프로그래밍(OOP) 패러다임을 따릅니다. 파이썬의 디자인 철학은 코드 가독성과 간결성을 강조하며, 개발자가 빠르게 프로그램을 작성하고 테스트할 수 있도록 돕습니다.\n",
      "\n",
      "**파이썬의 특징**\n",
      "\n",
      "파이썬의 주요 특징은 다음과 같습니다.\n",
      "\n",
      "1. **쉬운 학습 곡선**: 파이썬은 간단하고 직관적인 문법을 가지고 있어, 프로그래밍을 처음 시작하는 사람들도 쉽게 배울 수 있습니다.\n",
      "2. **고수준 언어**: 파이썬은 하드웨어와 운영 체제 레벨의 복잡성을 추상화하여, 개발자가 비즈니스 로직에 집중할 수 있도록 합니다.\n",
      "3. **동적 타이핑**: 파이썬은 변수의 타입을 선언할 필요가 없으며, 실행 시에 타입이 결정됩니다.\n",
      "4. **객체 지향 프로그래밍**: 파이썬은 OOP 패러다임을 지원하며, 클래스, 객체, 상속, 다형성 등의 개념을 포함합니다.\n",
      "5. **대규모 라이브러리**: 파이썬은 방대한 라이브러리와 모듈을 보유하고 있어, 다양한 분야에서 활용할 수 있습니다.\n",
      "\n",
      "**파이썬의 활용 분야**\n",
      "\n",
      "파이썬은 다양한 분야에서 사용됩니다.\n",
      "\n",
      "1. **웹 개발**: 파이썬은 웹 개발을 위해 Flask, Django 등의 프레임워크를 제공합니다.\n",
      "2. **데이터 과학**: 파이썬은 데이터 과학을 위해 NumPy, pandas, scikit-learn 등의 라이브러리를 제공합니다.\n",
      "3. **인공지능**: 파이썬은 인공지능을 위해 TensorFlow, Keras 등의 라이브러리를 제공합니다.\n",
      "4. **자동화**: 파이썬은 자동화를 위해 Robot Framework 등의 라이브러리를 제공합니다.\n",
      "5. **교육**: 파이썬은 교육 기관에서 프로그래밍 입문 언어로 널리 사용됩니다.\n",
      "\n",
      "**파이썬의 버전**\n",
      "\n",
      "파이썬은 두 가지 주요 버전으로 나뉩니다.\n",
      "\n",
      "1. **파이썬 2.x**: 2000년에 출시된 파이썬 2.x는 2015년에 지원이 중단되었습니다.\n",
      "2. **파이썬 3.x**: 2008년에 출시된 파이썬 3.x는 현재 가장 최신의 버전이며, 활발하게 지원되고 있습니다.\n",
      "\n",
      "**결론**\n",
      "\n",
      "파이썬은 쉽고 강력한 프로그래밍 언어입니다. 파이썬은 다양한 분야에서 활용되며, 개발자가 빠르게 프로그램을 작성하고 테스트할 수 있도록 돕습니다. 파이썬은 교육 기관에서 프로그래밍 입문 언어로 널리 사용되며, 개발자들 사이에서 인기가 있습니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(type(response.content))\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be6835",
   "metadata": {},
   "source": [
    "LCEL\n",
    "Prompt + LLM을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0e483ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='\\n    You are an expert in AI Expert. Answer the question. \\n    <Question>: {input}에 대해 쉽게 설명해주세요.\")\\n    ')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an expert in AI Expert. Answer the question. \n",
    "    <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "    \"\"\")                                     \n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "918cd610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a67e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCEL\n",
    "Prompt + LLM + OutputParser을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0277560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain 연결 (LCEL) prompt + llm + outputparser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain2 = prompt | llm | output_parser\n",
    "print(type(chain2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa763d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# chain 호출\n",
    "try:\n",
    "    result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e927295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LangChain은 다양한 제품과 도구를 제공하여 개발자와 기업이 인공지능(AI) 기술을 보다 쉽게 통합하고 활용할 수 있도록 지원합니다. LangChain의 주요 제품 중 LangSmith와 LangServe에 대해 설명드리겠습니다.\n",
      "\n",
      "### LangSmith\n",
      "\n",
      "LangSmith는 LangChain에서 제공하는 플랫폼으로, 개발자가 랭체인 기반의 애플리케이션을 더 쉽게 개발, 테스트, 배포할 수 있도록 설계되었습니다. LangSmith를 통해 개발자는 다음과 같은 작업을 보다 효율적으로 수행할 수 있습니다:\n",
      "\n",
      "- **개발 환경 제공**: LangChain의 기능을 활용하여 랭체인 기반 애플리케이션을 개발할 수 있는 통합 환경을 제공합니다.\n",
      "- **워크플로우 관리**: 복잡한 데이터 처리 및 AI 워크플로를 쉽게 관리하고 시각화할 수 있습니다.\n",
      "- **에이전트 관리**: 다양한 AI 에이전트를 관리하고, 그들의 상호 작용을 조정할 수 있습니다.\n",
      "- **데이터 관리**: AI 모델의 학습과 추론에 필요한 데이터를 효과적으로 관리할 수 있습니다.\n",
      "\n",
      "LangSmith는 개발자가 AI 기반 애플리케이션을 구축하고 운영하는 데 필요한 다양한 기능을 제공합니다.\n",
      "\n",
      "### LangServe\n",
      "\n",
      "LangServe는 LangChain에서 제공하는 또 다른 중요한 제품으로, LangChain 애플리케이션의 배포 및 운영을 간소화합니다. LangServe를 통해 사용자는 다음과 같은 이점을 누릴 수 있습니다:\n",
      "\n",
      "- **API 제공**: LangChain 애플리케이션에 대한 RESTful API를 자동으로 생성해 줌으로써, 클라이언트 애플리케이션이 서버와 통신할 수 있는 인터페이스를 제공합니다.\n",
      "- **확장성**: 대규모 트래픽과 요청을 효율적으로 처리하도록 설계되어, 애플리케이션의 확장성을 보장합니다.\n",
      "- **모니터링 및 로그 관리**: 배포된 애플리케이션의 성능을 모니터링하고, 로그를 관리하여 문제 해결을 돕습니다.\n",
      "\n",
      "LangServe는 LangChain 애플리케이션을 프로덕션 환경에 배포하고 관리하는 데 있어 중요한 역할을 합니다.\n",
      "\n",
      "### 기타 제품\n",
      "\n",
      "LangChain은 LangSmith와 LangServe 외에도 다양한 다른 도구와 제품을 제공하고 있습니다. 이들 제품은 특정 작업이나 산업에 특화되어 있으며, 개발자와 기업이 AI 기술을 활용할 수 있는 다양한 솔루션을 제공합니다.\n",
      "\n",
      "- **LangChain SDK**: LangChain의 핵심 기능에 접근하고, 애플리케이션을 구축하기 위한 소프트웨어 개발 키트입니다.\n",
      "- **LangChain 커뮤니티**: LangChain 사용자와 개발자가 서로 소통하고, 지식과 경험을 공유하는 플랫폼입니다.\n",
      "\n",
      "이러한 제품과 도구를 통해 LangChain은 개발자와 기업이 AI 기술을 보다 쉽고 효율적으로 활용할 수 있도록 지원하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \": LangChain의 Products(제품)는 어떤 것들이 있나요? 예를 들어 LangSmith, LangServe 같은 Product가 있어\"})\n",
    "    print(type(result))\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed6c0a8",
   "metadata": {},
   "source": [
    "Runnable의 stream() 함수 호출  \n",
    "\n",
    "스트리밍 출력을 위한 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "faa5746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리를 쉽게 설명해 드리겠습니다.\n",
      "\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 사람은 경험을 통해 학습하고, 인공지능 모델도 데이터를 통해 학습합니다.\n",
      "\n",
      "**인공지능 모델 학습 과정**\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해 필요한 데이터를 수집합니다. 이 데이터는 문제에 대한 답을 포함하고 있어야 합니다.\n",
      "2. **데이터 전처리**: 수집한 데이터를 깨끗하게 정리하고, 필요한 경우 데이터를 변환하거나 가공합니다.\n",
      "3. **모델 초기화**: 인공지능 모델을 초기화합니다. 모델은 신경망 구조로 구성되어 있으며, 가중치와 편향이 무작위로 설정됩니다.\n",
      "4. **순전파**: 입력 데이터를 모델에 넣고, 출력값을 계산합니다. 이 과정은 입력 데이터를 통해 모델이 예측하는 과정입니다.\n",
      "5. **오차 계산**: 예측한 출력값과 실제 출력값(데이터에 포함된 답) 사이의 오차를 계산합니다.\n",
      "6. **역전파**: 오차를 역으로 계산하여, 모델의 가중치와 편향을 업데이트합니다. 이 과정은 모델이 학습하는 과정입니다.\n",
      "7. **최적화**: 가중치와 편향을 업데이트하여, 오차를 최소화합니다.\n",
      "\n",
      "**학습의 핵심**\n",
      "\n",
      "인공지능 모델의 학습은 가중치와 편향을 업데이트하는 과정입니다. 이 과정은 반복적으로 수행되며, 모델은 데이터를 통해 학습합니다.\n",
      "\n",
      "* **가중치 업데이트**: 가중치는 입력 데이터와 출력값 사이의 관계를 나타냅니다. 가중치를 업데이트함으로써, 모델은 입력 데이터와 출력값 사이의 관계를 더 잘 이해하게 됩니다.\n",
      "* **편향 업데이트**: 편향은 출력값의 평균을 나타냅니다. 편향을 업데이트함으로써, 모델은 출력값의 평균을 더 잘 예측하게 됩니다.\n",
      "\n",
      "**학습의 종료**\n",
      "\n",
      "인공지능 모델의 학습은 오차가 일정 수준 이하로 떨어질 때까지 수행됩니다. 오차가 일정 수준 이하로 떨어지면, 모델은 학습을 완료한 상태입니다.\n",
      "\n",
      "이렇게 인공지능 모델은 데이터를 통해 학습하고, 가중치와 편향을 업데이트하여 문제를 해결하는 능력을 향상시킵니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "try:\n",
    "    answer = chain2.stream({\"input\": \"인공지능 모델의 학습 원리를 자세하게 설명해 주세요.\"})\n",
    "    \n",
    "    # 스트리밍 출력\n",
    "    #print(answer)\n",
    "    for token in answer:\n",
    "        # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "        print(token, end=\"\", flush=True)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d10240d",
   "metadata": {},
   "source": [
    "### Multi Chain\n",
    "**첫번째 Chain의 출력이, 두번째 Chain의 입력이 된다.**\n",
    "**두개의 Chain과 Prompt + OutputParser를 LCEL로 연결하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a42ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추전한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 줄거리를 3문장으로 요약해 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f08e764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**영화: 범죄도시2**\n",
      "\n",
      "범죄도시2는 마동석이 주연을 맡은 대한민국에서 가장 많은 관객을 동원한 영화 중 하나입니다. 이 영화는 강력반이 베트남으로 출장을 가서 마약 범죄조직을 소탕하는 내용입니다. 영화는 범죄도시1에 이어 더욱 화려한 액션과 스토리로 많은 관객들의 사랑을 받았습니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "try:\n",
    "    chain2 = (\n",
    "        {\"movie\": chain1}  # chain1의 출력을 movie 입력 변수로 전달\n",
    "        | prompt2\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "    response = chain2.invoke({\"genre\": \"한국영화액션\"})\n",
    "    print(response)  \n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e818190",
   "metadata": {},
   "source": [
    "### PromptTemplate 여러개 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "155c4323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "ChatGPT는 대규모 언어 모델로, 수십억 개의 매개변수를 가지고 있습니다. 이 모델은 다양한 텍스트 데이터를 학습하여 언어 패턴과 구조를 이해하며, 이를 통해 새로운 텍스트를 생성할 수 있습니다. 학습 과정에서 모델은 주어진 문장의 다음 단어를 예측하는 방식으로 학습합니다.\n",
      "\n",
      "ChatGPT 모델의 장점은 다음과 같습니다.\n",
      "\n",
      "*   자연스러운 대화 생성: ChatGPT는 대화의 맥락을 이해하고 자연스러운 응답을 생성할 수 있습니다.\n",
      "*   지식 정보 제공: ChatGPT는 다양한 분야에서 방대한 지식을 가지고 있어 사용자에게 정보를 제공할 수 있습니다.\n",
      "*   창의적 콘텐츠 생성: ChatGPT는 창의적인 콘텐츠, 예를 들어 시나 이야기, 코드, 이메일, 문서, 보고서, 메시지 등을 생성할 수 있습니다.\n",
      "\n",
      "ChatGPT 모델과 비슷한 AI 모델은 다음과 있습니다.\n",
      "\n",
      "*   LLaMA\n",
      "*   PaLM\n",
      "*   BERT\n",
      "*   XLNet\n",
      "*   LaMDA\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 요약해서 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"영어\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"영어\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05f2dd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 2 문장으로 요약해서 한국어로 답변해 주세요.', 'Gemma 모델의 학습 원리를 3 문장으로 요약해서 한국어로 답변해 주세요.', 'llama-4 모델의 학습 원리를 4 문장으로 요약해서 한국어로 답변해 주세요.']\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 요약해서 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 2},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 3},\n",
    "    {\"model_name\": \"llama-4\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05efad18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 모델은 대규모의 텍스트 데이터를 학습하여 언어 패턴과 구조를 이해하고, 이를 바탕으로 새로운 텍스트를 생성하는 인공지능 모델입니다. 이 모델은 강화 학습 및 지도 학습을 사용하여 미세 조정되었으며 인터넷, 책 및 대화에서 얻은 방대한 양의 데이터를 학습했습니다.\n",
      "Gemma 모델은 주어진 문맥을 기반으로 다음 토큰을 예측하는 자기 지도 학습 방식을 사용합니다. 이 과정에서 대규모 텍스트 데이터를 학습하여 언어의 패턴과 구조를 이해하게 됩니다. 학습된 패턴과 구조를 바탕으로 Gemma는 자연어 처리 작업에서 높은 성능을 발휘할 수 있습니다.\n",
      "llama-4 모델은 메타에서 개발한 대규모 언어 모델입니다. 이 모델은 방대한 텍스트 데이터를 기반으로 학습되며, 이를 통해 자연어 처리 능력을 향상시킵니다. 학습 과정에서 llama-4는 주어진 문맥에서 다음에 올 단어를 예측하도록 훈련되며, 이 과정을 통해 언어의 패턴과 구조를 학습합니다. 이를 통해 llama-4는 다양한 자연어 처리 작업에 활용될 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    response = llm.invoke(prompt) #AIMessage\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e664bd24",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate  \n",
    "\n",
    "SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14da0191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "딥러닝은 인공신경망을 기반으로 하는 머신러닝의 한 분야입니다. 인공신경망은 인간의 뇌를 모방한 구조로, 데이터를 처리하고 학습하는 방식입니다. 딥러닝은 이러한 인공신경망을 깊게 쌓아 올린 구조를 사용합니다. \n",
      "\n",
      "즉, 여러개의 레이어를 가진 심층 신경망을 활용하여 데이터를 분석하고 학습하는 기술로, **컴퓨터가 스스로 학습할 수 있도록** 합니다. \n",
      "\n",
      "주로 이미지나 음성, 자연어 처리 등에 사용됩니다. 예를 들어, 이미지 인식, 얼굴 인식, 음성 인식, 언어 번역, 자율 주행 자동차 등이 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"당신은 {topic} 전문가입니다. 명확하고 자세하게 한국어로 설명해 주세요.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"딥러닝은 무엇인가요?\")\n",
    "\n",
    "# LLM 호출\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eb3e44",
   "metadata": {},
   "source": [
    "### FewShotPromptTemplate\n",
    "예시를 제공 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbb5cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = final_prompt | model\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"태양계의 행성들을 간략히 정리해 주세요.\"})\n",
    "#result = chain.invoke({\"input\": \"양자 얽힘이 무엇인가요?\"})\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-AGfTwH54-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
