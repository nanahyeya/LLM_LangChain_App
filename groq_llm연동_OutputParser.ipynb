{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c937cddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77167827",
   "metadata": {},
   "source": [
    "### CommaSeparatedListOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556a26b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={'format_instructions': 'Return a JSON object.'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê³¼í•™ ë¶„ì•¼ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ì²´ê³„ì ì´ê³  ê°„ê²°í•œ ë‹µë³€ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'question'], input_types={}, partial_variables={}, template='#Format: {format_instructions}\\n\\n#Question: {question}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "# JSON ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ê³¼í•™ ë¶„ì•¼ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ì²´ê³„ì ì´ê³  ê°„ê²°í•œ ë‹µë³€ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.\"),\n",
    "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# JSON ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ì„ í”„ë¡¬í”„íŠ¸ì— ì ìš©\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0190832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"mission_name\": \"ë‰´í˜¸ë¼ì´ì¦ŒìŠ¤\",\n",
      "        \"goal\": \"ëª…ì™•ì„± íƒì‚¬\",\n",
      "        \"agency\": \"NASA\"\n",
      "    },\n",
      "    {\n",
      "        \"mission_name\": \"ì¹´ì‹œë‹ˆ-í˜¸ì´ê²ìŠ¤\",\n",
      "        \"goal\": \"í† ì„±ì˜ ìœ„ì„± íƒ€ì´íƒ„ íƒì‚¬\",\n",
      "        \"agency\": \"NASA, ESA, ì´íƒˆë¦¬ì•„ ìš°ì£¼êµ­\"\n",
      "    },\n",
      "    {\n",
      "        \"mission_name\": \"ì°½ì–´ 4í˜¸\",\n",
      "        \"goal\": \"ë‹¬ì˜ ë’·ë©´ íƒì‚¬\",\n",
      "        \"agency\": \"ì¤‘êµ­ ìš°ì£¼êµ­\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# OpenAI ëª¨ë¸ ì„¤ì •\n",
    "#model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ëŠ” ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì§ˆë¬¸ ì„¤ì • (ìš°ì£¼ íƒì‚¬ ê´€ë ¨ ì§ˆë¬¸)\n",
    "question = \"ìµœê·¼ 10ë…„ê°„ ì§„í–‰ëœ ì£¼ìš” ìš°ì£¼ íƒì‚¬ ë¯¸ì…˜ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. \\\n",
    "ê° ë¯¸ì…˜ì˜ ì´ë¦„ì€ `mission_name`ì—, ëª©í‘œëŠ” `goal`ì—, ì£¼ê´€ ê¸°ê´€ì€ `agency`ì— ë‹´ì•„ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ ë° JSON ì‘ë‹µ ë°›ê¸°\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "# JSON ë°ì´í„° ì¶œë ¥\n",
    "print(json.dumps(response, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0749b1b1",
   "metadata": {},
   "source": [
    "### JsonOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb231e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "# JSON ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ê³¼í•™ ë¶„ì•¼ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ì²´ê³„ì ì´ê³  ê°„ê²°í•œ ë‹µë³€ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.\"),\n",
    "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# JSON ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ì„ í”„ë¡¬í”„íŠ¸ì— ì ìš©\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a12e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"mission_name\": \"ë‰´í˜¸ë¼ì´ì¦ŒìŠ¤\",\n",
      "        \"goal\": \"ëª…ì™•ì„± íƒì‚¬\",\n",
      "        \"agency\": \"NASA\"\n",
      "    },\n",
      "    {\n",
      "        \"mission_name\": \"ì¹´ì‹œë‹ˆ-í˜¸ì´ê²ìŠ¤\",\n",
      "        \"goal\": \"í† ì„±ì˜ ìœ„ì„± íƒ€ì´íƒ„ íƒì‚¬\",\n",
      "        \"agency\": \"NASA, ESA, ì´íƒˆë¦¬ì•„ ìš°ì£¼êµ­\"\n",
      "    },\n",
      "    {\n",
      "        \"mission_name\": \"ì°½ì–´ 4í˜¸\",\n",
      "        \"goal\": \"ë‹¬ì˜ ë’·ë©´ íƒì‚¬\",\n",
      "        \"agency\": \"ì¤‘êµ­ ìš°ì£¼êµ­\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# OpenAI ëª¨ë¸ ì„¤ì •\n",
    "# model = ChatOpenAI(model=\"meta-llama/llama-4-scout-17b-16e-instruct\", temperature=0)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "# í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ëŠ” ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì§ˆë¬¸ ì„¤ì • (ìš°ì£¼ íƒì‚¬ ê´€ë ¨ ì§ˆë¬¸)\n",
    "question = \"ìµœê·¼ 10ë…„ê°„ ì§„í–‰ëœ ì£¼ìš” ìš°ì£¼ íƒì‚¬ ë¯¸ì…˜ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. \\\n",
    "ê° ë¯¸ì…˜ì˜ ì´ë¦„ì€ `mission_name`ì—, ëª©í‘œëŠ” `goal`ì—, ì£¼ê´€ ê¸°ê´€ì€ `agency`ì— ë‹´ì•„ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ ë° JSON ì‘ë‹µ ë°›ê¸°\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "# JSON ë°ì´í„° ì¶œë ¥\n",
    "print(json.dumps(response, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a432aaff",
   "metadata": {},
   "source": [
    "### PandasDataFrameOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e94e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Instructions:\n",
      " The output should be formatted as a string as the operation, followed by a colon, followed by the column or row to be queried on, followed by optional array parameters.\n",
      "1. The column names are limited to the possible columns below.\n",
      "2. Arrays must either be a comma-separated list of numbers formatted as [1,3,5], or it must be in range of numbers formatted as [0..4].\n",
      "3. Remember that arrays are optional and not necessarily required.\n",
      "4. If the column is not in the possible columns or the operation is not a valid Pandas DataFrame operation, return why it is invalid as a sentence starting with either \"Invalid column\" or \"Invalid operation\".\n",
      "\n",
      "As an example, for the formats:\n",
      "1. String \"column:num_legs\" is a well-formatted instance which gets the column num_legs, where num_legs is a possible column.\n",
      "2. String \"row:1\" is a well-formatted instance which gets row 1.\n",
      "3. String \"column:num_legs[1,2]\" is a well-formatted instance which gets the column num_legs for rows 1 and 2, where num_legs is a possible column.\n",
      "4. String \"row:1[num_legs]\" is a well-formatted instance which gets row 1, but for just column num_legs, where num_legs is a possible column.\n",
      "5. String \"mean:num_legs[1..3]\" is a well-formatted instance which takes the mean of num_legs from rows 1 to 3, where num_legs is a possible column and mean is a valid Pandas DataFrame operation.\n",
      "6. String \"do_something:num_legs\" is a badly-formatted instance, where do_something is not a valid Pandas DataFrame operation.\n",
      "7. String \"mean:invalid_col\" is a badly-formatted instance, where invalid_col is not a possible column.\n",
      "\n",
      "Here are the possible columns:\n",
      "```\n",
      "Survived, Pclass, Name, Sex, Age, Siblings/Spouses Aboard, Parents/Children Aboard, Fare\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.output_parsers import PandasDataFrameOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import re\n",
    "\n",
    "# Titanic ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# Pandas DataFrame Output Parser ì„¤ì •\n",
    "parser = PandasDataFrameOutputParser(dataframe=df)\n",
    "\n",
    "# í˜•ì‹ ì§€ì¹¨ ì¶œë ¥\n",
    "format_instructions = parser.get_format_instructions()\n",
    "print(\"Format Instructions:\\n\", format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6cfd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived, Pclass, Name, Sex, Age, Siblings/Spouses Aboard, Parents/Children Aboard, Fare\n"
     ]
    }
   ],
   "source": [
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "# model = ChatOpenAI(\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    You are a helpful assistant that interacts with a Pandas DataFrame.\n",
    "    The DataFrame contains the following columns: {columns}.\n",
    "    \n",
    "    Your task is to answer the user's query by generating a command in the following format:\n",
    "    {format_instructions}\n",
    "    \n",
    "    User Query: {query}    \n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": format_instructions,\n",
    "        \"columns\": \", \".join(df.columns)\n",
    "    },\n",
    ")\n",
    "print(prompt.partial_variables['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89302056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name ì»¬ëŸ¼ ì¶œë ¥\n",
      "ì²«ë²ˆì§¸ í–‰ ì¶œë ¥\n",
      "ì˜¤ë¥˜ ë°œìƒ: Request 'The operation \"head\" is typically used to show the first few rows, but in this case, you want to show only the first row. A well-formatted command for this would be:\n",
      "\n",
      "head:0\n",
      "\n",
      "However, since you specifically asked to \"Show first row\", I will use the \"iloc\" operation which is used for integer-location based indexing.\n",
      "\n",
      "The command will be:\n",
      " \n",
      "row:0 \n",
      "\n",
      "If you want to get a specific column for the first row, you can do:\n",
      "\n",
      "row:0[Survived] \n",
      "\n",
      "Let me know if you need anything else!' is not correctly formatted.                     Please refer to the format instructions.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ëª¨ë¸ ì‘ë‹µ ë°›ê¸°\n",
    "try:\n",
    "    # **Name ì—´ì„ í‘œì‹œí•˜ì‹­ì‹œì˜¤.**\n",
    "    print('Name ì»¬ëŸ¼ ì¶œë ¥')\n",
    "    df_query = \"Show the Name column\"\n",
    "\n",
    "    # parser_output = chain.invoke({\"query\": df_query})\n",
    "    # print(type(parser_output))\n",
    "    # print(parser_output)\n",
    "\n",
    "        # **ì²«ë²ˆì§¸ í–‰ì„ í‘œì‹œí•˜ì‹­ì‹œì˜¤.**\n",
    "    print('ì²«ë²ˆì§¸ í–‰ ì¶œë ¥')\n",
    "    df_query2 = \"Show first row\"\n",
    "\n",
    "    parser_output2 = chain.invoke({\"query\": df_query2})\n",
    "    print(parser_output2)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce4466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "# model = ChatOpenAI(\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "# ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"data\", description=\"A list of dictionaries representing table rows.\"),\n",
    "]\n",
    "\n",
    "# Output Parser ì„¤ì •\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an AI assistant that generates tabular data. \n",
    "    You must return the data in JSON format that follows this schema:\n",
    "    \n",
    "    {format_instructions}\n",
    "        \n",
    "    **User Query:**\n",
    "    {query}\n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff28c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ì²´ì¸ ìƒì„± (í”„ë¡¬í”„íŠ¸ â†’ ëª¨ë¸ â†’ OutputParser)\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì‹¤í–‰ í•¨ìˆ˜\n",
    "def generate_dataframe(user_query):\n",
    "    try:\n",
    "        # ëª¨ë¸ í˜¸ì¶œ\n",
    "        json_response = chain.invoke({\"query\": user_query})\n",
    "\n",
    "        # ëª¨ë¸ì´ ë°˜í™˜í•œ JSONì„ Pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "        df = pd.DataFrame(json_response[\"data\"])\n",
    "\n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        print(\"\\nğŸ”¹ Generated DataFrame:\\n\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b0f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024ë…„ í•˜ë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±\n",
      "\n",
      "ğŸ”¹ Generated DataFrame:\n",
      "\n",
      "(8, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "      <th>Average Price</th>\n",
       "      <th>Number of Transactions</th>\n",
       "      <th>Year-over-Year Change (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seocho-gu</td>\n",
       "      <td>1450000000</td>\n",
       "      <td>1100</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Songpa-gu</td>\n",
       "      <td>1300000000</td>\n",
       "      <td>1050</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yongsan-gu</td>\n",
       "      <td>1250000000</td>\n",
       "      <td>900</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gwanak-gu</td>\n",
       "      <td>800000000</td>\n",
       "      <td>700</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dongdaemun-gu</td>\n",
       "      <td>850000000</td>\n",
       "      <td>750</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        District  Average Price  Number of Transactions  \\\n",
       "3      Seocho-gu     1450000000                    1100   \n",
       "4      Songpa-gu     1300000000                    1050   \n",
       "5     Yongsan-gu     1250000000                     900   \n",
       "6      Gwanak-gu      800000000                     700   \n",
       "7  Dongdaemun-gu      850000000                     750   \n",
       "\n",
       "   Year-over-Year Change (%)  \n",
       "3                        3.8  \n",
       "4                        3.2  \n",
       "5                        2.9  \n",
       "6                        1.5  \n",
       "7                        2.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [ì˜ˆì œ 1] 2024ë…„ ìƒë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±\n",
    "print('2024ë…„ í•˜ë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±')\n",
    "df_seoul_housing = generate_dataframe(\n",
    "    \"Create a dataset of the average apartment sale prices in Seoul for the second half of 2024 with columns: District (êµ¬), Average Price (in KRW), Number of Transactions, and Year-over-Year Change (%).\"\n",
    ")\n",
    "print(df_seoul_housing.shape)\n",
    "df_seoul_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0330f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'generate_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# [ì˜ˆì œ 2] 2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df_seoul_subway = \u001b[43mgenerate_dataframe\u001b[49m(\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mGenerate a dataset of the top 10 busiest subway stations in Seoul in 2024 with columns: Station Name, Line Number, Daily Passenger Volume, and Weekday vs Weekend Ratio.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df_seoul_subway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      7\u001b[39m     df_seoul_subway.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'generate_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "print('2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°')\n",
    "# [ì˜ˆì œ 2] 2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°\n",
    "df_seoul_subway = generate_dataframe(\n",
    "    \"Generate a dataset of the top 10 busiest subway stations in Seoul in 2024 with columns: Station Name, Line Number, Daily Passenger Volume, and Weekday vs Weekend Ratio.\"\n",
    ")\n",
    "if df_seoul_subway is not None:\n",
    "    df_seoul_subway.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ece1d39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜\n",
      "âŒ ì˜¤ë¥˜ ë°œìƒ: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# [ì˜ˆì œ 3] í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜\u001b[39;00m\n\u001b[32m      3\u001b[39m df_korean_convenience_stores = generate_dataframe(\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCreate a dataset of the top 5 convenience store brands in Korea in 2024 with columns: Brand Name, Number of Stores, Total Revenue (in billion KRW), and Market Share (\u001b[39m\u001b[33m%\u001b[39m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mdf_korean_convenience_stores\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhead\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "print('í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜')\n",
    "# [ì˜ˆì œ 3] í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜\n",
    "df_korean_convenience_stores = generate_dataframe(\n",
    "    \"Create a dataset of the top 5 convenience store brands in Korea in 2024 with columns: Brand Name, Number of Stores, Total Revenue (in billion KRW), and Market Share (%).\"\n",
    ")\n",
    "df_korean_convenience_stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0735341",
   "metadata": {},
   "source": [
    "### PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac2bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add pydantic\n",
    "# %pip install pydantic \n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08469092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶œë ¥ êµ¬ì¡°ë¥¼ ì •ì˜í•˜ëŠ” Pydantic ëª¨ë¸\n",
    "class MovieRecommendation(BaseModel):\n",
    "    movie_title: str = Field(description=\"ì¶”ì²œ ì˜í™” ì œëª©\")\n",
    "    reason: str = Field(description=\"ì¶”ì²œ ì´ìœ \")\n",
    "    genre: List[str] = Field(description=\"ì˜í™” ì¥ë¥´\")\n",
    "    estimated_rating: float = Field(description=\"10ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \")\n",
    "    \n",
    "# Pydantic ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = PydanticOutputParser(pydantic_object=MovieRecommendation)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "template = \"\"\"\n",
    "ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì˜í™”ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n",
    "ìš”ì²­: {query}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# íŒŒì„œì˜ ì§€ì‹œì‚¬í•­ì„ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…\n",
    "prompt = prompt.partial(\n",
    "    format_instructions=parser.get_format_instructions()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74c20e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶”ì²œ ì˜í™”: The Sixth Sense (1999)\n",
      "ì¶”ì²œ ì´ìœ : 1990ë…„ëŒ€ ëŒ€í‘œì ì¸ ì‹¬ë¦¬ ê³µí¬ ì˜í™”ë¡œ, ë°˜ì „ì˜ ë¬˜ë¯¸ê°€ ìˆëŠ” í´ë˜ì‹í•œ ëŠë‚Œì˜ ì˜í™”ì…ë‹ˆë‹¤.\n",
      "ì¥ë¥´: ê³µí¬, ë¯¸ìŠ¤í„°ë¦¬, ìŠ¤ë¦´ëŸ¬\n",
      "ì˜ˆìƒ í‰ì : 8.5/10\n"
     ]
    }
   ],
   "source": [
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "#model = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„± ë° ì‹¤í–‰\n",
    "query = \"1990ë…„ëŒ€ í´ë˜ì‹í•œ ëŠë‚Œì˜ ê³µí¬ ì˜í™” ì¶”ì²œí•´ì¤˜\"\n",
    "chain = prompt | model | parser\n",
    "output = chain.invoke({\"query\": query})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ì¶”ì²œ ì˜í™”: {output.movie_title}\")\n",
    "print(f\"ì¶”ì²œ ì´ìœ : {output.reason}\")\n",
    "print(f\"ì¥ë¥´: {', '.join(output.genre)}\")\n",
    "print(f\"ì˜ˆìƒ í‰ì : {output.estimated_rating}/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec679d6",
   "metadata": {},
   "source": [
    "### StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb469858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­:\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"rating\": string  // 5ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \n",
      "\t\"pros\": string  // ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ì¥ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\n",
      "\t\"cons\": string  // ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ë‹¨ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\n",
      "\t\"summary\": string  // ë¦¬ë·°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½\n",
      "}\n",
      "```\n",
      "===== ë¶„ì„ ê²°ê³¼ =====\n",
      "{'cons': ['ê°€ê²©ì´ ë¹„ì‹¸ë‹¤',\n",
      "          'ë¬´ê²Œê°€ ë¬´ê±°ì›Œì„œ ì†ì´ í”¼ê³¤í•  ìˆ˜ ìˆë‹¤',\n",
      "          'ë‹¨ì  3ë²ˆì§¸ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì‹  ê¸°ì¬í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.'],\n",
      " 'pros': ['ë°°í„°ë¦¬ ìˆ˜ëª…ì´ ì¢‹ë‹¤', 'ì¹´ë©”ë¼ í™”ì§ˆì´ ì„ ëª…í•˜ë‹¤', 'ì•¼ê°„ ëª¨ë“œê°€ í›Œë¥­í•˜ë‹¤'],\n",
      " 'rating': '4',\n",
      " 'summary': 'ìŠ¤ë§ˆíŠ¸í°ì˜ ë°°í„°ë¦¬ ìˆ˜ëª…ê³¼ ì¹´ë©”ë¼ í™”ì§ˆì— ë§Œì¡±í–ˆì§€ë§Œ, ê°€ê²©ê³¼ ë¬´ê²Œê°€ ë‹¤ì†Œ ë¶€ë‹´ìŠ¤ëŸ½ë‹¤ëŠ” ë¦¬ë·°ì…ë‹ˆë‹¤.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# ì¶œë ¥ êµ¬ì¡° ì •ì˜ (í‰ì , ì¥ì , ë‹¨ì , ìš”ì•½)\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"rating\", description=\"5ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \"),\n",
    "    ResponseSchema(name=\"pros\", description=\"ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ì¥ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\"),\n",
    "    ResponseSchema(name=\"cons\", description=\"ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ë‹¨ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\"),\n",
    "    ResponseSchema(name=\"summary\", description=\"ë¦¬ë·°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½\")\n",
    "]\n",
    "\n",
    "# íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "print(\"ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­:\")\n",
    "print(format_instructions)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "template = \"\"\"\n",
    "ë‹¤ìŒ ì œí’ˆ ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ì„¸ìš”. ë¦¬ë·° ë‚´ìš©: {review}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™” (temperature=0.5ë¡œ ì„¤ì •í•´ ì¼ê´€ì„± ìˆëŠ” ì¶œë ¥)\n",
    "#model = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë¦¬ë·° ë°ì´í„°\n",
    "review = \"\"\"\n",
    "ì´ ìŠ¤ë§ˆíŠ¸í°ì€ ë°°í„°ë¦¬ ìˆ˜ëª…ì´ ì •ë§ ì¢‹ì•„ì„œ í•˜ë£¨ ì¢…ì¼ ì‚¬ìš©í•´ë„ ì¶©ì „ì´ í•„ìš” ì—†ì—ˆì–´ìš”. \n",
    "ì¹´ë©”ë¼ í™”ì§ˆë„ ì„ ëª…í•˜ê³ , íŠ¹íˆ ì•¼ê°„ ëª¨ë“œê°€ í›Œë¥­í•©ë‹ˆë‹¤. \n",
    "ë‹¤ë§Œ ê°€ê²©ì´ ì¡°ê¸ˆ ë¹„ì‹¸ê³ , ë¬´ê²Œê°€ 200gì´ ë„˜ì–´ì„œ ì†ì´ í”¼ê³¤í•  ìˆ˜ ìˆì–´ìš”.\n",
    "\"\"\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "chain = prompt | model | parser\n",
    "\n",
    "output = chain.invoke({\"review\": review})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥ (Pretty Print)\n",
    "print(\"===== ë¶„ì„ ê²°ê³¼ =====\")\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b607415",
   "metadata": {},
   "source": [
    "### DatetimeOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1463a627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:35:26.834442\n",
      "ë‚ ì§œ ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­:\n",
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 1534-11-20T22:09:52.514526Z, 0666-08-12T22:46:39.780258Z, 0033-01-16T09:50:34.682341Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(datetime.today())\n",
    "\n",
    "# ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™” (ì‹œê°„ëŒ€ í¬í•¨ ê°€ëŠ¥)\n",
    "datetime_parser = DatetimeOutputParser()\n",
    "format_instructions = datetime_parser.get_format_instructions()\n",
    "\n",
    "print(\"ë‚ ì§œ ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­:\")\n",
    "print(format_instructions)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "# í˜„ì¬ ë‚ ì§œë¥¼ ëª…ì‹œì ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "template = f\"\"\"\n",
    "í˜„ì¬ ë‚ ì§œ: {current_date}\n",
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ/ì‹œê°„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. ìƒëŒ€ì  í‘œí˜„(ì˜ˆ: 'ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼')ì€ í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "í…ìŠ¤íŠ¸: {{text}}\n",
    "\n",
    "{{format_instructions}}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f6f1c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: íšŒì˜ëŠ” 2025ë…„ 6ì›” 15ì¼ ì˜¤í›„ 2ì‹œì— ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "ì¶”ì¶œëœ ë‚ ì§œ: 2025-06-15 14:00:00 \n",
      "\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: í”„ë¡œì íŠ¸ ë§ˆê°ì¼ì€ ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼ì…ë‹ˆë‹¤.\n",
      "ì¶”ì¶œëœ ë‚ ì§œ: 2025-06-20 00:00:00 \n",
      "\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: í–‰ì‚¬ ì‹œì‘: 7/25/2025 18:00 KST\n",
      "ì¶”ì¶œëœ ë‚ ì§œ: 2025-07-25 18:00:00 \n",
      "\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: 3ì¼ í›„ì— ì‹œìŠ¤í…œ ì ê²€ì´ ì§„í–‰ë©ë‹ˆë‹¤.\n",
      "ì¶”ì¶œëœ ë‚ ì§œ: 2025-06-14 00:00:00 \n",
      "ì´ í…ìŠ¤íŠ¸ì—ì„œ ì´ë²¤íŠ¸ ë‚ ì§œ/ì‹œê°„ ì¶”ì¶œ:\n",
      "\n",
      "- ì´ë²¤íŠ¸ëª…: í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë§ˆì¼“\n",
      "- ë‚ ì§œ: 2025-12-10 00:00:00\n",
      "\n",
      "- ì´ë²¤íŠ¸ëª…: í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ì´ë¸Œ íŒŒí‹°\n",
      "- ë‚ ì§œ: 2025-12-24 00:00:00\n",
      "\n",
      "- ì´ë²¤íŠ¸ëª…: ìƒˆí•´ ì¹´ìš´íŠ¸ë‹¤ìš´\n",
      "- ë‚ ì§œ: 2025-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™” (temperature=0.1ë¡œ ì„¤ì •í•´ ì •í™•í•œ ë‚ ì§œ ì¶œë ¥ ê°•ì¡°)\n",
    "#model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° (ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ í¬í•¨)\n",
    "texts = [\n",
    "    \"íšŒì˜ëŠ” 2025ë…„ 6ì›” 15ì¼ ì˜¤í›„ 2ì‹œì— ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\",\n",
    "    \"í”„ë¡œì íŠ¸ ë§ˆê°ì¼ì€ ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼ì…ë‹ˆë‹¤.\",\n",
    "    \"í–‰ì‚¬ ì‹œì‘: 7/25/2025 18:00 KST\",\n",
    "    \"3ì¼ í›„ì— ì‹œìŠ¤í…œ ì ê²€ì´ ì§„í–‰ë©ë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥\n",
    "chain = prompt | model | datetime_parser\n",
    "\n",
    "for text in texts:\n",
    "    print(f\"\\nì›ë³¸ í…ìŠ¤íŠ¸: {text}\")\n",
    "    output = chain.invoke({\"text\": text})\n",
    "    print(f\"ì¶”ì¶œëœ ë‚ ì§œ: {output.strftime('%Y-%m-%d %H:%M:%S %Z')}\")\n",
    "\n",
    "    \n",
    "# ì´ë²¤íŠ¸ ì¶”ì¶œìš© í”„ë¡¬í”„íŠ¸\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "event_template = \"\"\"\n",
    "í˜„ì¬ ë‚ ì§œ: {current_date}\n",
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ì´ë²¤íŠ¸ì˜ ë‚ ì§œ/ì‹œê°„ì„ ì¶”ì¶œí•˜ì„¸ìš”. ê° ì´ë²¤íŠ¸ëŠ” ì´ë¦„ê³¼ ë‚ ì§œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "í…ìŠ¤íŠ¸: {text}\n",
    "\n",
    "ì¶œë ¥ í˜•ì‹:\n",
    "- ì´ë²¤íŠ¸ëª…: [ì´ë¦„]\n",
    "- ë‚ ì§œ: [YYYY-MM-DD HH:MM:SS]\n",
    "\"\"\"\n",
    "\n",
    "event_prompt = ChatPromptTemplate.from_template(event_template)\n",
    "event_chain = event_prompt | model\n",
    "\n",
    "# ì˜ˆì‹œ í…ìŠ¤íŠ¸ (ì—¬ëŸ¬ ì´ë²¤íŠ¸ í¬í•¨)\n",
    "event_text = \"\"\"\n",
    "12ì›” 10ì¼ì— í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë§ˆì¼“ì´ ì—´ë¦¬ê³ , 12ì›” 24ì¼ì—ëŠ” í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ì´ë¸Œ íŒŒí‹°ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "ë˜í•œ 1ì›” 1ì¼ 00:00ì— ìƒˆí•´ ì¹´ìš´íŠ¸ë‹¤ìš´ì´ ì§„í–‰ë  ì˜ˆì •ì…ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "print(event_chain.invoke({\"current_date\":current_date, \"text\": event_text}).content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-AGfTwH54-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
